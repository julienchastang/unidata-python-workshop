{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"top\"></a>\n",
    "<div style=\"width:1000 px\">\n",
    "\n",
    "<div style=\"float:right; width:98 px; height:98px;\">\n",
    "<img src=\"https://raw.githubusercontent.com/Unidata/MetPy/master/metpy/plots/_static/unidata_150x150.png\" alt=\"Unidata Logo\" style=\"height: 98px;\">\n",
    "</div>\n",
    "\n",
    "<h1>Advanced Surface Observations: Working with Mesonet Data</h1>\n",
    "<h3>Unidata Python Workshop</h3>\n",
    "\n",
    "<div style=\"clear:both\"></div>\n",
    "</div>\n",
    "\n",
    "<hr style=\"height:2px;\">\n",
    "\n",
    "<div style=\"float:right; width:250 px\"><img src=\"http://weather-geek.net/images/metar_what.png\" alt=\"METAR\" style=\"height: 200px;\"></div>\n",
    "\n",
    "## Overview:\n",
    "\n",
    "* **Teaching:** 30 minutes\n",
    "* **Exercises:** 35 minutes\n",
    "\n",
    "### Questions\n",
    "1. How do I read in complicated mesonet data with Pandas?\n",
    "1. How do I merge multiple Pandas DataFrames?\n",
    "1. What's the best way to make a station plot of data?\n",
    "1. How can I make a time series of data from one station?\n",
    "\n",
    "### Objectives\n",
    "1. <a href=\"#reading\">Read Mesonet data with Pandas</a>\n",
    "2. <a href=\"#merge\">Merge multiple Pandas DataFrames together </a>\n",
    "3. <a href=\"#plot\">Plot mesonet data with MetPy and CartoPy</a>\n",
    "4. <a href=\"#timeseries\">Create time series plots of station data</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"reading\"></a>\n",
    "# Reading Mesonet Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we're going to use the Pandas library to read text-based data. Pandas is excellent at handling text, csv, and other files. However, you have to help Pandas figure out how your data is formatted sometimes. Lucky for you, mesonet data frequently comes in forms that are not the most user-friendly. Through this notebook, we'll see how these complicated datasets can be handled nicely by Pandas to create useful station plots for hand analysis or publication. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Pandas\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### West Texas Mesonet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [West Texas Mesonet](http://www.depts.ttu.edu/nwi/research/facilities/wtm/index.php) is a wonderful data source for researchers and storm chasers alike! We have some 5-minute observations from the entire network on 22 March 2019 that we'll analyze in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can parse time into a nice internal storage format as we read in the file. If the time is specified in the file in a somewhat standard form, pandas will even guess at the format if you tell it which column to use. However, in this case the time is reported in a horrible format: between one and four characters that, if there are four characters, represent hours and minutes as HHMM. Let's turn take a charater string, turn it into an integer, and then use integer string formatting to write out a four character string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in ['0', '05', '100', '1005']:\n",
    "    print('{0:04d}'.format(int(t)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas can be told how to parse non-standard dates formats by writing an arbitrary function that takes a string and returns a datetime. Here's what that function looks like in this case. We can use timedelta to convert hours and minutes, and then add them to the start date using date math."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tx_date(v, start_date=None):\n",
    "    s = '{0:04d}'.format(int(v)) # regularize the data to a four character string\n",
    "    hour = pd.to_timedelta(int(s[0:2]), 'hour') \n",
    "    minute = pd.to_timedelta(int(s[2:4]), 'minute')\n",
    "    return start_date + hour + minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in the data and handle the lines that cause issues\n",
    "\n",
    "# Get a nice date variable cooresponding to the start time\n",
    "start_date = pd.datetime.strptime('2019-03-22', '%Y-%m-%d')\n",
    "print(start_date)\n",
    "\n",
    "# Pre-apply the start date to our date parsing function, so that pandas only passes one value\n",
    "from functools import partial\n",
    "date_parser = partial(parse_tx_date, start_date=start_date)\n",
    "\n",
    "filename = 'West_Texas_data/FIVEMIN_82.txt'\n",
    "tx_data = pd.read_csv(filename, delimiter=',', header=None, error_bad_lines=False, warn_bad_lines=False,\n",
    "                     parse_dates=[2], date_parser=date_parser\n",
    "                     )\n",
    "tx_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be understandable\n",
    "tx_data.columns = ['Array_ID', 'QC_flag', 'Time', 'Station_ID', '10m_scalar_wind_speed',\n",
    "                 '10m_vector_wind_speed', '10m_wind_direction',\n",
    "                 '10m_wind_direction_std', '10m_wind_speed_std', \n",
    "                 '10m_gust_wind_speed', '1.5m_temperature', \n",
    "                 '9m_temperature', '2m_temperature', \n",
    "                 '1.5m_relative_humidity', 'station_pressure', 'rainfall', \n",
    "                 'dewpoint', '2m_wind_speed', 'solar_radiation']\n",
    "tx_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The West Texas mesonet provides data on weather, agriculture, and radiation. These different observations are encoded 1, 2, and 3, respectively in the Array ID column. Let's parse out only the meteorological data for this exercise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove non-meteorological rows\n",
    "tx_data = tx_data[tx_data['Array_ID'] == 1]\n",
    "tx_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Station pressure is 600 hPa lower than it should be, so let's correct that as well!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct presssure \n",
    "tx_data['station_pressure'] += 600\n",
    "tx_data['station_pressure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, let's read in the station metadata file for the West Texas mesonet, so that we can have coordinates to plot data later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tx_stations = pd.read_csv('WestTexas_stations.csv')\n",
    "tx_stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Oklahoma Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try reading in the Oklahoma Mesonet data located in the `201903222300.mdf` file using Pandas. Check out the documentation on Pandas if you run into issues! Make sure to handle missing values as well. Also read in the Oklahoma station data from the `Oklahoma_stations.csv` file. Only read in the station ID, latitude, and longitude columns from that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_ok_date(v, start_date=None):\n",
    "    s = '{0:04d}'.format(int(v)) # regularize the data to a four character string\n",
    "    minute = pd.to_timedelta(int(s), 'minute')\n",
    "    return start_date + minute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/read_ok.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"merge\"></a>\n",
    "# Merging DataFrames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have two data files per mesonet - one for the data itself and one for the metadata. It would be really nice to combine these DataFrames together into one for each mesonet. Pandas has some built in methods to do this - see [here](https://pandas.pydata.org/pandas-docs/stable/user_guide/merging.html). For this example, we'll be using the `merge` method. First, let's rename columns in the Oklahoma station DataFrame to be more understandable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns so merging can occur\n",
    "ok_stations.columns = ['STID', 'LAT', 'LON']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conveniently, we have a `STID` column in both DataFrames. Let's base our merge on that and see what we get!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the two data frames based on the Station ID\n",
    "ok_data = pd.merge(ok_data, ok_stations, on='STID')\n",
    "ok_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That was nice! But what if our DataFrames don't have the same column name, and we want to avoid renaming columns? Check out the documentation for `pd.merge` and see how we can merge the West Texas DataFrames together. Also, subset the data to only be from 2300 UTC, which is when our Oklahoma data was taken. Call the new DataFrame `tx_one_time`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/merge_texas.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"plot\"></a>\n",
    "# Creating a Station Plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say we want to plot temperature, dewpoint, and wind barbs. Given our data from the two mesonets, do we have what we need? If not, use MetPy to calculate what you need!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import metpy.calc as mpcalc\n",
    "from metpy.units import units\n",
    "\n",
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/data_conversion.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's make a Station Plot with our data using MetPy and CartoPy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from metpy.plots import StationPlot\n",
    "import cartopy.crs as ccrs\n",
    "import cartopy.feature as cfeature\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a plot with map features\n",
    "fig = plt.figure(figsize=(12, 12))\n",
    "proj = ccrs.Stereographic(central_longitude=-100, central_latitude=35)\n",
    "ax = fig.add_subplot(1, 1, 1, projection=proj)\n",
    "ax.add_feature(cfeature.STATES.with_scale('50m'), edgecolor='black')\n",
    "ax.gridlines()\n",
    "\n",
    "\n",
    "# Create a station plot pointing to an Axes to draw on as well as the location of points\n",
    "stationplot = StationPlot(ax, ok_data['LON'].values, ok_data['LAT'].values, transform=ccrs.PlateCarree(),\n",
    "                          fontsize=10)\n",
    "stationplot.plot_parameter('NW', ok_data['TAIR'], color='red')\n",
    "stationplot.plot_parameter('SW', ok_dewpoint, color='green')\n",
    "stationplot.plot_barb(ok_u, ok_v)\n",
    "\n",
    "# Texas Data\n",
    "stationplot = StationPlot(ax, tx_one_time['Long'].values, tx_one_time['Lat'].values, transform=ccrs.PlateCarree(),\n",
    "                          fontsize=10)\n",
    "stationplot.plot_parameter('NW', tx_one_time['2m_temperature'], color='red')\n",
    "stationplot.plot_parameter('SW', tx_one_time['dewpoint'], color='green')\n",
    "stationplot.plot_barb(tx_u, tx_v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an informative plot, but is rather crowded. Using MetPy's `reduce_point_density` function, try cleaning up this plot to something that would be presentable/publishable. This function will return a mask, which you'll apply to all arrays in the plotting commands to filter down the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Oklahoma\n",
    "xy = proj.transform_points(ccrs.PlateCarree(), ok_data['LON'].values, ok_data['LAT'].values)\n",
    "# Reduce point density so that there's only one point within a 50km circle\n",
    "ok_mask = mpcalc.reduce_point_density(xy, 50000)\n",
    "\n",
    "# Texas\n",
    "\n",
    "# Your code here\n",
    "\n",
    "# Plot\n",
    "\n",
    "# Your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/reduce_and_plot.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a name=\"timeseries\"></a>\n",
    "# Creating Time Series for Stations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to take data from all times from a single station to make a time series (or meteogram) plot? How can we easily do that with Pandas without having to aggregate the data by hand? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Select daylight hours\n",
    "tx_daytime = tx_data[(tx_data['Time'] >= '2019-03-22 06:00') & (tx_data['Time'] <= '2019-03-22 20:00')]\n",
    "\n",
    "# Create sub-tables for each station\n",
    "tx_grp = tx_daytime.groupby('ID')\n",
    "\n",
    "# Get data from station DIMM\n",
    "station_data = tx_grp.get_group('DIMM')\n",
    "\n",
    "# Create hourly averaged data\n",
    "# time_bins = pd.cut(station_data['Time'], np.arange(600, 2100, 100))\n",
    "# xarray has groupby_bins, but pandas has cut\n",
    "station_data.index=station_data['Time']\n",
    "station_hourly = station_data.resample('H')\n",
    "\n",
    "\n",
    "# station_hourly = station_data.groupby(time_bins)\n",
    "station_hourly_mean = station_hourly.mean()\n",
    "station_hourly_mean = station_hourly_mean.reset_index() # no longer index by time so that we get it back as a regular variable.\n",
    "\n",
    "# The times are reported at the beginning of the interval, but really represent \n",
    "# the mean symmetric about the half hour. Let's fix that.\n",
    "# from datetime import timedelta timedelta(minutes=30) #\n",
    "station_hourly_mean['Time'] += pd.to_timedelta(30, 'minutes')\n",
    "print(station_hourly_mean['Time'])\n",
    "print(station_data['Time'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the data above to make a time series plot of the instantaneous data and the hourly averaged data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/mesonet_timeseries.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "conda-env-unidata-python-workshop-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
